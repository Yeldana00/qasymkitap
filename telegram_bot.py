# telegram_bot.py
import pandas as pd
import psycopg2 # –ò—Å–ø–æ–ª—å–∑—É–µ–º psycopg2 –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton
from telegram.ext import (
    Application, CommandHandler, MessageHandler, 
    filters, ContextTypes
)
import logging
import os
from dotenv import load_dotenv

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ---
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ–∫—Ä–µ—Ç–æ–≤ ---
load_dotenv() 
TOKEN = os.getenv("TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")

# --- (1) –ñ–ê“¢–ê–†–¢–´–õ“í–ê–ù –õ–û–ì–ò–ö–ê: –î–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –∂“Ø–∫—Ç–µ—É –∂”ô–Ω–µ –º–æ–¥–µ–ª—å–¥—ñ –¥–∞–π—ã–Ω–¥–∞—É ---

def load_data_from_db():
    """
    PostgreSQL-–¥–µ–Ω –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –∂“Ø–∫—Ç–µ–π–¥—ñ, –¥—É–±–ª–∏–∫–∞—Ç—Ç–∞—Ä–¥—ã –∞–ª—ã–ø —Ç–∞—Å—Ç–∞–π–¥—ã,
    —Ç–∞“õ—ã—Ä—ã–ø—Ç–∞—Ä“ì–∞ —Å–∞–ª–º–∞“õ “õ–æ—Å–∞–¥—ã (x3) –∂”ô–Ω–µ TF-IDF –º–æ–¥–µ–ª—ñ–Ω –¥–∞–π—ã–Ω–¥–∞–π–¥—ã.
    –°–æ–Ω–¥–∞–π-–∞“õ –±–∞—Ç—ã—Ä–º–∞–ª–∞—Ä “Ø—à—ñ–Ω —Å–∞–Ω–∞—Ç—Ç–∞—Ä —Ç—ñ–∑—ñ–º—ñ–Ω “õ–∞–π—Ç–∞—Ä–∞–¥—ã.
    """
    if not DATABASE_URL:
        logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: DATABASE_URL –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        exit()
        
    try:
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL...")
        with psycopg2.connect(DATABASE_URL) as conn:
            sql = "SELECT * FROM books"
            df = pd.read_sql_query(sql, conn)
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∫–Ω–∏–≥ –∏–∑ –ë–î.")
        
        # --- –î–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ —Ç–∞–∑–∞–ª–∞—É (test_model.py –∞–ª—ã–Ω“ì–∞–Ω) ---
        df = df.drop_duplicates(subset=['–ê—Ç—ã'])
        logger.info(f"–î—É–±–ª–∏–∫–∞—Ç—Ç–∞—Ä –∞–ª—ã–Ω—ã–ø —Ç–∞—Å—Ç–∞–ª–¥—ã. “ö–∞–ª“ì–∞–Ω—ã: {len(df)} –∫—ñ—Ç–∞–ø.")

        df['–ê—Ç—ã'] = df['–ê—Ç—ã'].fillna('')
        df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].fillna('–ë–µ–ª–≥—ñ—Å—ñ–∑')
        df['–¢–æ–ª—ã“ì—ã—Ä–∞“õ'] = df['–¢–æ–ª—ã“ì—ã—Ä–∞“õ'].fillna('')
        df['–ê–≤—Ç–æ—Ä'] = df['–ê–≤—Ç–æ—Ä'].fillna('')

        category_mapping = {cat: i for i, cat in enumerate(df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].unique())}
        df['Category_Numeric'] = df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].map(category_mapping).fillna(-1)

        kazakh_stop_words = [
            '–∂”ô–Ω–µ', '–Ω–µ–º–µ—Å–µ', '–±—ñ—Ä–∞“õ', '“Ø—à—ñ–Ω', '–¥–µ–π—ñ–Ω', '–±–∞—Å—Ç–∞–ø', '–∂–æ“õ', '–±–∞—Ä', 
            '–±–∞—Ä–ª—ã“õ', '”ô—Ä', '–∫”©–ø', '–∞–∑', '–±–æ–ª–∞–¥—ã'
        ]
        
        tfidf_vectorizer = TfidfVectorizer(stop_words=kazakh_stop_words)
        
        # --- –ñ–∞“õ—Å–∞—Ä—Ç—É (test_model.py –∞–ª—ã–Ω“ì–∞–Ω) ---
        logger.info("–£–ª—É—á—à–µ–Ω–∏–µ: –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–∞ (–ù–∞–∑–≤–∞–Ω–∏–µ x3)...")
        df['combined'] = (
            (df['–ê—Ç—ã'].str.lower() * 3) + ' ' + # <--- –£–õ–£–ß–®–ï–ù–ò–ï
            df['–¢–æ–ª—ã“ì—ã—Ä–∞“õ'].str.lower() + ' ' + 
            df['–ê–≤—Ç–æ—Ä'].str.lower() + ' ' + 
            df['Category_Numeric'].astype(str)
        )
        
        tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined'])
        
        logger.info("–ú–æ–¥–µ–ª—å TF-IDF (–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –∏ –ú–∞—Ç—Ä–∏—Ü–∞) –≥–æ—Ç–æ–≤–∞!")
        
        # --- –ë–∞—Ç—ã—Ä–º–∞–ª–∞—Ä “Ø—à—ñ–Ω —Å–∞–Ω–∞—Ç—Ç–∞—Ä–¥—ã –∞–ª—É ---
        categories = [cat for cat in df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].unique() if cat != '–ë–µ–ª–≥—ñ—Å—ñ–∑']
        top_categories = sorted(categories)[:9] # –ê–ª“ì–∞—à“õ—ã 9-—ã–Ω –∞–ª–∞–º—ã–∑ (–Ω–µ–º–µ—Å–µ —Å“±—Ä—ã–ø—Ç–∞–π–º—ã–∑)
        
        return df, tfidf_vectorizer, tfidf_matrix, top_categories

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î: {e}")
        exit()

# --- –ì–ª–æ–±–∞–ª–¥—ã –∞–π–Ω—ã–º–∞–ª—ã–ª–∞—Ä: 1 —Ä–µ—Ç –∂“Ø–∫—Ç–µ—É ---
books_df, tfidf, tfidf_matrix, TOP_CATEGORIES = load_data_from_db()

# --- –¢“±—Ä–∞“õ—Ç—ã –ø–µ—Ä–Ω–µ—Ç–∞“õ—Ç–∞–Ω—ã “õ“±—Ä—É ---
# 3x3 —Ç–æ—Ä (grid) –∂–∞—Å–∞–π–º—ã–∑
keyboard_layout = [TOP_CATEGORIES[i:i + 3] for i in range(0, len(TOP_CATEGORIES) - (len(TOP_CATEGORIES) % 3), 3)]
# “ö–∞–ª“ì–∞–Ω –±–∞—Ç—ã—Ä–º–∞–ª–∞—Ä–¥—ã “õ–æ—Å–∞–º—ã–∑
remaining = TOP_CATEGORIES[len(TOP_CATEGORIES) - (len(TOP_CATEGORIES) % 3):]
if remaining:
    keyboard_layout.append(remaining)

PERSISTENT_KEYBOARD = ReplyKeyboardMarkup(keyboard_layout, resize_keyboard=True)

# --- (2) –Ü–ó–î–ï–£ –ñ”ò–ù–ï –§–û–†–ú–ê–¢–¢–ê–£ –õ–û–ì–ò–ö–ê–°–´ ---

def find_books_by_keywords(query: str) -> pd.DataFrame:
    """
    –ö—ñ–ª—Ç—Ç—ñ–∫ —Å”©–∑–¥–µ—Ä –±–æ–π—ã–Ω—à–∞ –∫—ñ—Ç–∞–ø—Ç–∞—Ä–¥—ã —ñ–∑–¥–µ–π–¥—ñ, TF-IDF –º–æ–¥–µ–ª—ñ–Ω “õ–æ–ª–¥–∞–Ω–∞–¥—ã.
    (–ë“±–ª —Ñ—É–Ω–∫—Ü–∏—è –µ–Ω–¥—ñ –∂–∞“ª–∞–Ω–¥—ã“õ 'tfidf' –∂”ô–Ω–µ 'tfidf_matrix' –∞–π–Ω—ã–º–∞–ª—ã–ª–∞—Ä—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω–∞–¥—ã)
    """
    try:
        query = query.lower()
        query_vector = tfidf.transform([query])
        scores = cosine_similarity(query_vector, tfidf_matrix).flatten()
        
        if scores.max() == 0:
            return pd.DataFrame() # –ï—à—Ç–µ“£–µ —Ç–∞–±—ã–ª–º–∞–¥—ã

        top_indices = scores.argsort()[:-6:-1]
        top_scores = scores[top_indices]
        valid_indices = top_indices[top_scores > 0]
        
        if len(valid_indices) == 0:
            return pd.DataFrame()
            
        return books_df.iloc[valid_indices]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ find_books_by_keywords: {e}")
        return pd.DataFrame()

def format_book_message(book: pd.Series) -> str:
    """–ö—ñ—Ç–∞–ø —Ç—É—Ä–∞–ª—ã –∞“õ–ø–∞—Ä–∞—Ç—Ç—ã —Ñ–æ—Ä–º–∞—Ç—Ç–∞–π–¥—ã (”©–∑–≥–µ—Ä—ñ—Å—Å—ñ–∑)"""
    if pd.notna(book['–ë–∞“ì–∞—Å—ã']):
        price = f"{book['–ë–∞“ì–∞—Å—ã']:,.0f} —Ç–≥".replace(',', ' ')
    else:
        price = "–ë–∞“ì–∞—Å—ã –±–µ–ª–≥—ñ—Å—ñ–∑"
    
    message = (
        f"üìö <b>{book['–ê—Ç—ã']}</b>\n"
        f"üë§ –ê–≤—Ç–æ—Ä—ã: {book['–ê–≤—Ç–æ—Ä']}\n"
        f"üóÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {book['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']}\n"
        f"üí∞ –ë–∞“ì–∞—Å—ã: {price}\n"
    )
    if pd.notna(book['URL']):
         message += f"üîó <a href=\"{book['URL']}\">–°–∞–π—Ç—Ç–∞–Ω “õ–∞—Ä–∞—É</a>\n"
    return message + "\n"

# --- (3) TELEGRAM –û–ë–†–ê–ë–û–¢–ß–ò–ö–¢–ï–†–Ü ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    /start –∫–æ–º–∞–Ω–¥–∞—Å—ã–Ω ”©“£–¥–µ—É—à—ñ.
    –°”ô–ª–µ–º–¥–µ—Å—É —Ö–∞–±–∞—Ä–ª–∞–º–∞—Å—ã–Ω –ñ”ò–ù–ï —Ç“±—Ä–∞“õ—Ç—ã –ø–µ—Ä–Ω–µ—Ç–∞“õ—Ç–∞–Ω—ã –∂—ñ–±–µ—Ä–µ–¥—ñ.
    """
    user = update.effective_user
    await update.message.reply_html(
        f"–°”ô–ª–µ–º, {user.mention_html()}! üëã\n\n"
        f"–¢”©–º–µ–Ω–¥–µ–≥—ñ —Å–∞–Ω–∞—Ç—Ç—ã (–∫–∞—Ç–µ–≥–æ—Ä–∏—è–Ω—ã) —Ç–∞“£–¥–∞“£—ã–∑, –Ω–µ–º–µ—Å–µ –∫—ñ—Ç–∞–ø –∞—Ç–∞—É—ã–Ω/—Å–∏–ø–∞—Ç—Ç–∞–º–∞—Å—ã–Ω –∂–∞–∑—ã“£—ã–∑:",
        reply_markup=PERSISTENT_KEYBOARD # <--- –ñ–ê“¢–ê –¢“∞–†–ê“ö–¢–´ –ü–ï–†–ù–ï–¢–ê“ö–¢–ê
    )

async def handle_category_click(category_name: str, update: Update):
    """
    –°–∞–Ω–∞—Ç –±–∞—Ç—ã—Ä–º–∞—Å—ã –±–∞—Å—ã–ª“ì–∞–Ω–¥–∞ —ñ—Å–∫–µ “õ–æ—Å—ã–ª–∞–¥—ã.
    –û—Å—ã —Å–∞–Ω–∞—Ç—Ç–∞–Ω –∫–µ–∑–¥–µ–π—Å–æ“õ –∫—ñ—Ç–∞–ø—Ç–∞—Ä–¥—ã –∫”©—Ä—Å–µ—Ç–µ–¥—ñ.
    """
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category_name}")
    category_books = books_df[books_df['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] == category_name]
    
    if category_books.empty:
        await update.message.reply_text(f"<b>{category_name}</b> —Å–∞–Ω–∞—Ç—ã–Ω–¥–∞ –∫—ñ—Ç–∞–ø—Ç–∞—Ä —Ç–∞–±—ã–ª–º–∞–¥—ã.", parse_mode='HTML')
        return
        
    sample_books = category_books.sample(min(5, len(category_books)))
    response_message = f"<b>{category_name}</b> —Å–∞–Ω–∞—Ç—ã–Ω–¥–∞“ì—ã –∫–µ–∑–¥–µ–π—Å–æ“õ –∫—ñ—Ç–∞–ø—Ç–∞—Ä:\n\n"
    for _, book in sample_books.iterrows():
        response_message += format_book_message(book)
    # –¢“±—Ä–∞“õ—Ç—ã –ø–µ—Ä–Ω–µ—Ç–∞“õ—Ç–∞–Ω—ã “õ–∞–π—Ç–∞ –∂—ñ–±–µ—Ä—É–¥—ñ“£ “õ–∞–∂–µ—Ç—ñ –∂–æ“õ, –æ–ª –æ—Ä–Ω—ã–Ω–¥–∞ “õ–∞–ª–∞–¥—ã.
    await update.message.reply_html(response_message, disable_web_page_preview=True)

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ë–ê–†–õ–´“ö –∫—ñ—Ä—ñ—Å –º”ô—Ç—ñ–Ω–¥—ñ ”©“£–¥–µ–π–¥—ñ.
    –ú”ô—Ç—ñ–Ω–Ω—ñ“£ –±–∞—Ç—ã—Ä–º–∞ –Ω–µ–º–µ—Å–µ —ñ–∑–¥–µ—É —Å”©–∑—ñ –µ–∫–µ–Ω—ñ–Ω —Ç–µ–∫—Å–µ—Ä–µ–¥—ñ.
    """
    query_text = update.message.text
    
    # –¢–ï–ö–°–ï–†–£: –ë“±–ª –±–∞—Ç—ã—Ä–º–∞ –º–∞, ”ô–ª–¥–µ —ñ–∑–¥–µ—É –º–µ?
    if query_text in TOP_CATEGORIES:
        # –ï–≥–µ—Ä –±“±–ª –±—ñ–∑–¥—ñ“£ –±–∞—Ç—ã—Ä–º–∞–ª–∞—Ä–¥—ã“£ –±—ñ—Ä—ñ –±–æ–ª—Å–∞:
        await handle_category_click(query_text, update)
    else:
        # –ï–≥–µ—Ä –±“±–ª –∫”ô–¥—ñ–º–≥—ñ —ñ–∑–¥–µ—É —Å”©–∑—ñ –±–æ–ª—Å–∞:
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç –ø–æ –∫–ª—é—á–∞–º: '{query_text}'")
        try:
            found_books = find_books_by_keywords(query_text)
            
            if found_books.empty:
                await update.message.reply_text("–ö–µ—à—ñ—Ä—ñ“£—ñ–∑, –æ—Å—ã —Å”©–∑–¥–µ—Ä –±–æ–π—ã–Ω—à–∞ –µ—à—Ç–µ“£–µ —Ç–∞–±—ã–ª–º–∞–¥—ã. üòï")
                return
                
            response_message = f"<b>'{query_text}'</b> —Å”©–∑–¥–µ—Ä—ñ –±–æ–π—ã–Ω—à–∞ —ñ–∑–¥–µ—É –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ:\n\n"
            for _, book in found_books.iterrows():
                response_message += format_book_message(book)
            await update.message.reply_html(response_message, disable_web_page_preview=True)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ –∫–ª—é—á–∞–º: {e}")
            await update.message.reply_text("–û–π, –±—ñ—Ä “õ–∞—Ç–µ–ª—ñ–∫ –æ—Ä—ã–Ω –∞–ª–¥—ã.")

def main():
    """–ë–æ–ª—Ç—ã —ñ—Å–∫–µ “õ–æ—Å—É (–±–∞—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏—è)"""
    if not TOKEN:
        logger.error("!!! –¢–û–ö–ï–ù –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù !!!")
        logger.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Ö–æ—Å—Ç–∏–Ω–≥–∞.")
        return

    application = Application.builder().token(TOKEN).build()
    
    # –ö–æ–º–∞–Ω–¥–∞–ª–∞—Ä
    application.add_handler(CommandHandler("start", start))
    
    # 'button_callback' –µ–Ω–¥—ñ “õ–∞–∂–µ—Ç –µ–º–µ—Å.
    # 'handle_text_message' –µ–Ω–¥—ñ –±”ô—Ä—ñ–Ω ”©“£–¥–µ–π–¥—ñ (–±–∞—Ç—ã—Ä–º–∞–ª–∞—Ä–¥—ã –¥–∞, —ñ–∑–¥–µ—É–¥—ñ –¥–µ).
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))

    logger.info("–ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    application.run_polling()

if __name__ == "__main__":
    main()

